# Web-Scrapper
A smart web srcaping tool that generates reports and creates directories for the PNG files and also charts. Scraps all websites

# ğŸ•·ï¸ Smart Web Scraper â€” Development Version

This is the **development-focused** version of the Smart Web Scraper. It includes debugging tools, live reload, and development-only features.

---

## ğŸ§© Overview
A Python-based Flask web scraper for structured data extraction, visualization, and report generation. The development mode enables developers to test scraping logic, tweak analysis, and improve the UI before production deployment.

---

## âš™ï¸ Setup for Development

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/smart-web-scraper.git
cd smart-web-scraper
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

If you donâ€™t have a `requirements.txt`, create one with:
```bash
Flask
requests
beautifulsoup4
pandas
matplotlib
selenium
reportlab
waitress
pytest
black
flake8
dotenv
```

---

## ğŸ§  Running the Scraper in Development Mode
Run Flask in debug mode to enable auto-reload and error logs:
```bash
flask --app scrapper run --debug
```

Or run directly:
```bash
python3 scrapper.py
```

---

## ğŸ§ª Testing
Use **pytest** for development testing:
```bash
pytest tests/
```

---

## ğŸ§± Directory Structure
```
scrapper-dev/
 â”œâ”€â”€ scrapper.py              # Core logic
 â”œâ”€â”€ templates/               # Dashboard HTML templates
 â”œâ”€â”€ static/                  # Frontend assets
 â”œâ”€â”€ modules/                 # Selenium and utility modules
 â”œâ”€â”€ scraped_data/            # Per-domain data folders
 â”œâ”€â”€ tests/                   # Unit/integration tests
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ README.md
```

---

## ğŸ§° Developer Tools
- **Black** for formatting: `black .`
- **Flake8** for linting: `flake8 .`
- **Selenium** for dynamic pages
- **Requests + BeautifulSoup** for static scraping

---

## ğŸ§® Data Insight Development
The `analyze_and_visualize()` function automatically detects numeric columns and generates multiple chart types:
- Histograms
- Pie charts
- Correlation heatmaps
- Line charts for time-based trends

Developers can extend this with new charting logic or integrate AI-assisted data summaries.

---

## ğŸ’¡ Development Notes
- Use proxy rotation for heavy scraping
- Implement `time.sleep()` or randomized delays to mimic human browsing
- Use environment variables from `.env` for configuration
- For headless scraping on Linux:
```bash
xvfb-run python3 scrapper.py
```

---

## ğŸ§‘â€ğŸ’» Contributing
1. Fork the repo
2. Create a new branch: `git checkout -b dev-feature`
3. Commit and push changes
4. Open a pull request

---

## ğŸ‘¥ Maintainer
**philip** â€” Lead developer and maintainer.

---

## ğŸ“œ License
MIT License â€” free for personal and educational development use.
